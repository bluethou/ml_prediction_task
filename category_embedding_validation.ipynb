{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "category_embedding의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQvMI3m7nSvk"
      },
      "source": [
        "EDAreport.html 파일을 먼저 확인해주시기 바랍니다.\n",
        "해당 파일은 R의 summarytools library를 이용해 작성한 train.csv파일의 데이터 탐색 결과이며, 이를 통해 다음과 같은 사실을 알 수 있습니다.\n",
        "1. integer features들의 치우친 분포(skewed distribution), 변수별 중위값 및 NA값의 비율\n",
        "2. catogorical features는 변수 당 최대 37774개의 항목이 있음\n",
        "3. 전체 2536535 레코드 중 137개가 중복됨\n",
        "4. 77.8%의 레코드가 0으로 라벨링 되었으며, 나머지 22.2%가 1 (sufficiently balanced)\n",
        "\n",
        "추가적으로, train, validation, test datasets의 Timestamp는 정렬된 상태임\n",
        "\n",
        "위 내용에 기반해 이 노트북은 추가적인 피쳐 엔지니어링 및 모델링을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g4LUXAWnSvq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import scipy\n",
        "from scipy import sparse\n",
        "import tensorflow as tf \n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzqRQmGmnWxH",
        "outputId": "fafdde53-ad5a-4509-8e81-94de3561ec51"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2wLnmU8nXaU"
      },
      "source": [
        "train = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/kakaobank_ml/train.csv\")\n",
        "val = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/kakaobank_ml/validation.csv\")\n",
        "test = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/kakaobank_ml/test.csv\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM38FbtAnSvs"
      },
      "source": [
        "Data imputation: integer features\n",
        "\n",
        "모든 정수형 변수들은 0또는 -1에 치우친 분포를 갖으므로, 평균값이 아닌 중위값으로 NaN을 대체.\n",
        "\n",
        "또한 isNaN 변수를 생성하여 data imputation후에도 모델 훈련시 이를 활용할 수 있도록 함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnSCGpURnSvt"
      },
      "source": [
        "def int_features_impute(df):\n",
        "    for i in range(1,9):\n",
        "        imputed_variable = 'integer_'+str(i)+'_wasNaN'\n",
        "        feature_name = 'integer_feature_'+str(i)\n",
        "        df.assign(imputed_variable = np.where(df[feature_name]!= df[feature_name], 1, 0))\n",
        "        df[feature_name].fillna((df[feature_name].median()), inplace=True)\n",
        "    return df"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_LX8ohznSvt"
      },
      "source": [
        "Data imputation: categorical features\n",
        "\n",
        "범주형 변수의 경우, NaN값을 문자열 'nan'으로 대체. \n",
        "\n",
        "추후 validation, test dataset에서 테스트 데이터에 없는 항목이 나올 경우 Out of Vocabulary (OOV)처리 예정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOnXa6iwnSvt"
      },
      "source": [
        "def fillna_unknown(df):\n",
        "    imputed_df = df.fillna('nan')\n",
        "    return imputed_df"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOoSNT_NiqR"
      },
      "source": [
        "train_df = int_features_impute(train)\n",
        "imputed_train = fillna_unknown(train_df)\n",
        "\n",
        "vali_df = int_features_impute(val)\n",
        "imputed_vali = fillna_unknown(vali_df)\n",
        "\n",
        "# test_df = int_features_impute(test)\n",
        "# test_df.pop('id')\n",
        "# imputed_test = fillna_unknown(test_df)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjHmMxirhIfB"
      },
      "source": [
        "Feature normalization\n",
        "\n",
        "기존의 수치형 피쳐를 정규화(평균 0, 표준편차 1)\n",
        "\n",
        "메모리 절약을 위해 추가적인 피쳐엔지니어링 전에 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj3yPWGshLEY"
      },
      "source": [
        "numeric_cols = ['click_timestamp', 'integer_feature_1', 'integer_feature_2',\n",
        "       'integer_feature_3', 'integer_feature_4', 'integer_feature_5',\n",
        "       'integer_feature_6', 'integer_feature_7', 'integer_feature_8']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNCyTqpnfZG-"
      },
      "source": [
        "scaler = StandardScaler() \n",
        "numeric_train = scaler.fit_transform( imputed_train[numeric_cols] ) \n",
        "numeric_vali = scaler.transform( imputed_vali[numeric_cols] ) "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCqRtUhChx6R"
      },
      "source": [
        "imputed_train[numeric_cols] = numeric_train\n",
        "imputed_vali[numeric_cols] = numeric_vali"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "xTHaRu1yiPSW",
        "outputId": "8a098ff5-f1a8-4bf7-97a9-62993400152e"
      },
      "source": [
        "imputed_train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>click_timestamp</th>\n",
              "      <th>integer_feature_1</th>\n",
              "      <th>integer_feature_2</th>\n",
              "      <th>integer_feature_3</th>\n",
              "      <th>integer_feature_4</th>\n",
              "      <th>integer_feature_5</th>\n",
              "      <th>integer_feature_6</th>\n",
              "      <th>integer_feature_7</th>\n",
              "      <th>integer_feature_8</th>\n",
              "      <th>categorical_feature_1</th>\n",
              "      <th>categorical_feature_2</th>\n",
              "      <th>categorical_feature_3</th>\n",
              "      <th>categorical_feature_4</th>\n",
              "      <th>categorical_feature_5</th>\n",
              "      <th>categorical_feature_6</th>\n",
              "      <th>categorical_feature_7</th>\n",
              "      <th>categorical_feature_8</th>\n",
              "      <th>categorical_feature_9</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.797944</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>-0.269290</td>\n",
              "      <td>-0.192979</td>\n",
              "      <td>-0.212794</td>\n",
              "      <td>-0.322726</td>\n",
              "      <td>82584581</td>\n",
              "      <td>572ee1a4</td>\n",
              "      <td>414baade</td>\n",
              "      <td>0ab261cb</td>\n",
              "      <td>4ab811c9</td>\n",
              "      <td>nan</td>\n",
              "      <td>f8cbd89d</td>\n",
              "      <td>776ce399</td>\n",
              "      <td>nan</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.797940</td>\n",
              "      <td>0.220638</td>\n",
              "      <td>0.668383</td>\n",
              "      <td>1.954428</td>\n",
              "      <td>0.078918</td>\n",
              "      <td>1.815397</td>\n",
              "      <td>-0.391918</td>\n",
              "      <td>-0.187862</td>\n",
              "      <td>-0.077319</td>\n",
              "      <td>4ba15056</td>\n",
              "      <td>9cc5f4bc</td>\n",
              "      <td>1f0cb5c0</td>\n",
              "      <td>c84c9c4e</td>\n",
              "      <td>6b4b1a1d</td>\n",
              "      <td>c82b2a00</td>\n",
              "      <td>9ac3fc32</td>\n",
              "      <td>3486227d</td>\n",
              "      <td>9a2a221f</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.797907</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>-0.269290</td>\n",
              "      <td>0.403839</td>\n",
              "      <td>-0.250288</td>\n",
              "      <td>-0.182493</td>\n",
              "      <td>9a9e5801</td>\n",
              "      <td>bbf70d82</td>\n",
              "      <td>0fb83956</td>\n",
              "      <td>2ff05004</td>\n",
              "      <td>ab2497dc</td>\n",
              "      <td>nan</td>\n",
              "      <td>862dcf90</td>\n",
              "      <td>e5ba7672</td>\n",
              "      <td>nan</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.797898</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>-0.269290</td>\n",
              "      <td>-0.192979</td>\n",
              "      <td>-0.246315</td>\n",
              "      <td>-0.322726</td>\n",
              "      <td>24ad6de8</td>\n",
              "      <td>243a7e36</td>\n",
              "      <td>9dc594c1</td>\n",
              "      <td>aacfa636</td>\n",
              "      <td>b3f7fb1d</td>\n",
              "      <td>nan</td>\n",
              "      <td>3f172b3f</td>\n",
              "      <td>3486227d</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.797886</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>-0.269290</td>\n",
              "      <td>0.204899</td>\n",
              "      <td>-0.250288</td>\n",
              "      <td>-0.094848</td>\n",
              "      <td>4f06a460</td>\n",
              "      <td>5911fc7e</td>\n",
              "      <td>d5b22f0b</td>\n",
              "      <td>cd57c18b</td>\n",
              "      <td>a8840224</td>\n",
              "      <td>nan</td>\n",
              "      <td>8d787bee</td>\n",
              "      <td>e5ba7672</td>\n",
              "      <td>nan</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   click_timestamp  integer_feature_1  ...  categorical_feature_9  label\n",
              "0        -1.797944          -0.158484  ...                    nan      0\n",
              "1        -1.797940           0.220638  ...               9a2a221f      0\n",
              "2        -1.797907          -0.158484  ...                    nan      0\n",
              "3        -1.797898          -0.158484  ...                    nan      1\n",
              "4        -1.797886          -0.158484  ...                    nan      0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JFhht8PbWdl"
      },
      "source": [
        "Time-series feature generation.\n",
        "\n",
        "이전과 현재 행들을 포함하여 2,5,10개 행들의 평균/표준편차를 피쳐로 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUVoLKBzS7LO"
      },
      "source": [
        "concat_df = pd.concat([imputed_train, imputed_vali],axis=0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE0Vr3whSvZk"
      },
      "source": [
        "window=2"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37cnadPDSy0a"
      },
      "source": [
        "def past_features_create(df, window=100):\n",
        "  for i in range(1,9):\n",
        "    df['avg_int'+str(i)] = df['integer_feature_'+str(i)].rolling(window=window).mean() \n",
        "    df['var_int'+str(i)] = df['integer_feature_'+str(i)].rolling(window=window).std() \n",
        "    df['avg_int'+str(i)+'_5'] = df['integer_feature_'+str(i)].rolling(window=window*5).mean() \n",
        "    df['var_int'+str(i)+'_5'] = df['integer_feature_'+str(i)].rolling(window=window*5).std() \n",
        "    df['avg_int'+str(i)+'_10'] = df['integer_feature_'+str(i)].rolling(window=window*10).mean() \n",
        "    df['var_int'+str(i)+'_10'] = df['integer_feature_'+str(i)].rolling(window=window*10).std() \n",
        "  return df"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWUzr5umS1ZW"
      },
      "source": [
        "concat_df_timefeatures = past_features_create(concat_df,  window=window).iloc[10*window-1:,:]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBNJcNjTTKaE"
      },
      "source": [
        "final_train = concat_df_timefeatures.iloc[:-len(val),:]\n",
        "final_vali = concat_df_timefeatures.iloc[-len(val):,:]\n",
        "# final_test = concat_df_timefeatures.iloc[-len(test):,:]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "ujiikvT0TgDW",
        "outputId": "146ad0f7-a95f-4e95-9730-47c1fb260998"
      },
      "source": [
        "final_train.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>click_timestamp</th>\n",
              "      <th>integer_feature_1</th>\n",
              "      <th>integer_feature_2</th>\n",
              "      <th>integer_feature_3</th>\n",
              "      <th>integer_feature_4</th>\n",
              "      <th>integer_feature_5</th>\n",
              "      <th>integer_feature_6</th>\n",
              "      <th>integer_feature_7</th>\n",
              "      <th>integer_feature_8</th>\n",
              "      <th>categorical_feature_1</th>\n",
              "      <th>categorical_feature_2</th>\n",
              "      <th>categorical_feature_3</th>\n",
              "      <th>categorical_feature_4</th>\n",
              "      <th>categorical_feature_5</th>\n",
              "      <th>categorical_feature_6</th>\n",
              "      <th>categorical_feature_7</th>\n",
              "      <th>categorical_feature_8</th>\n",
              "      <th>categorical_feature_9</th>\n",
              "      <th>label</th>\n",
              "      <th>avg_int1</th>\n",
              "      <th>var_int1</th>\n",
              "      <th>avg_int1_5</th>\n",
              "      <th>var_int1_5</th>\n",
              "      <th>avg_int1_10</th>\n",
              "      <th>var_int1_10</th>\n",
              "      <th>avg_int2</th>\n",
              "      <th>var_int2</th>\n",
              "      <th>avg_int2_5</th>\n",
              "      <th>var_int2_5</th>\n",
              "      <th>avg_int2_10</th>\n",
              "      <th>var_int2_10</th>\n",
              "      <th>avg_int3</th>\n",
              "      <th>var_int3</th>\n",
              "      <th>avg_int3_5</th>\n",
              "      <th>var_int3_5</th>\n",
              "      <th>avg_int3_10</th>\n",
              "      <th>var_int3_10</th>\n",
              "      <th>avg_int4</th>\n",
              "      <th>var_int4</th>\n",
              "      <th>avg_int4_5</th>\n",
              "      <th>var_int4_5</th>\n",
              "      <th>avg_int4_10</th>\n",
              "      <th>var_int4_10</th>\n",
              "      <th>avg_int5</th>\n",
              "      <th>var_int5</th>\n",
              "      <th>avg_int5_5</th>\n",
              "      <th>var_int5_5</th>\n",
              "      <th>avg_int5_10</th>\n",
              "      <th>var_int5_10</th>\n",
              "      <th>avg_int6</th>\n",
              "      <th>var_int6</th>\n",
              "      <th>avg_int6_5</th>\n",
              "      <th>var_int6_5</th>\n",
              "      <th>avg_int6_10</th>\n",
              "      <th>var_int6_10</th>\n",
              "      <th>avg_int7</th>\n",
              "      <th>var_int7</th>\n",
              "      <th>avg_int7_5</th>\n",
              "      <th>var_int7_5</th>\n",
              "      <th>avg_int7_10</th>\n",
              "      <th>var_int7_10</th>\n",
              "      <th>avg_int8</th>\n",
              "      <th>var_int8</th>\n",
              "      <th>avg_int8_5</th>\n",
              "      <th>var_int8_5</th>\n",
              "      <th>avg_int8_10</th>\n",
              "      <th>var_int8_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-1.797820</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>-0.26929</td>\n",
              "      <td>-0.391918</td>\n",
              "      <td>-0.175869</td>\n",
              "      <td>-0.235080</td>\n",
              "      <td>ac9c9952</td>\n",
              "      <td>ae46962e</td>\n",
              "      <td>ad3508b1</td>\n",
              "      <td>575579da</td>\n",
              "      <td>93b18cb5</td>\n",
              "      <td>nan</td>\n",
              "      <td>59a58e86</td>\n",
              "      <td>e5ba7672</td>\n",
              "      <td>nan</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>3.725290e-09</td>\n",
              "      <td>-0.120572</td>\n",
              "      <td>0.119889</td>\n",
              "      <td>-0.120572</td>\n",
              "      <td>0.116691</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.179454</td>\n",
              "      <td>0.2979</td>\n",
              "      <td>-0.179454</td>\n",
              "      <td>0.289954</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>1.435264e-09</td>\n",
              "      <td>-0.14332</td>\n",
              "      <td>0.363647</td>\n",
              "      <td>-0.091958</td>\n",
              "      <td>0.546051</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>3.725290e-09</td>\n",
              "      <td>-0.077143</td>\n",
              "      <td>0.150476</td>\n",
              "      <td>-0.099437</td>\n",
              "      <td>0.116633</td>\n",
              "      <td>-0.269290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.160819</td>\n",
              "      <td>0.343017</td>\n",
              "      <td>-0.110820</td>\n",
              "      <td>0.514028</td>\n",
              "      <td>-0.292449</td>\n",
              "      <td>0.140671</td>\n",
              "      <td>0.513255</td>\n",
              "      <td>1.385015</td>\n",
              "      <td>0.209873</td>\n",
              "      <td>1.025868</td>\n",
              "      <td>-0.050620</td>\n",
              "      <td>0.177128</td>\n",
              "      <td>-0.141035</td>\n",
              "      <td>0.126937</td>\n",
              "      <td>-0.162190</td>\n",
              "      <td>0.106953</td>\n",
              "      <td>0.054149</td>\n",
              "      <td>0.409031</td>\n",
              "      <td>0.015585</td>\n",
              "      <td>0.379035</td>\n",
              "      <td>-0.067678</td>\n",
              "      <td>0.298046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>-1.797820</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>-0.26929</td>\n",
              "      <td>-0.292449</td>\n",
              "      <td>-0.234889</td>\n",
              "      <td>-0.287667</td>\n",
              "      <td>faca1639</td>\n",
              "      <td>4807da4a</td>\n",
              "      <td>7fde5a70</td>\n",
              "      <td>23c80a6e</td>\n",
              "      <td>e69eaa04</td>\n",
              "      <td>nan</td>\n",
              "      <td>d2df39f3</td>\n",
              "      <td>e5ba7672</td>\n",
              "      <td>nan</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>3.725290e-09</td>\n",
              "      <td>-0.120572</td>\n",
              "      <td>0.119889</td>\n",
              "      <td>-0.120572</td>\n",
              "      <td>0.116691</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.179454</td>\n",
              "      <td>0.2979</td>\n",
              "      <td>-0.179454</td>\n",
              "      <td>0.289954</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>1.435264e-09</td>\n",
              "      <td>-0.14332</td>\n",
              "      <td>0.363647</td>\n",
              "      <td>-0.091958</td>\n",
              "      <td>0.546051</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>3.725290e-09</td>\n",
              "      <td>-0.077143</td>\n",
              "      <td>0.150476</td>\n",
              "      <td>-0.099437</td>\n",
              "      <td>0.116633</td>\n",
              "      <td>-0.269290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.160819</td>\n",
              "      <td>0.343017</td>\n",
              "      <td>-0.110820</td>\n",
              "      <td>0.514028</td>\n",
              "      <td>-0.342184</td>\n",
              "      <td>0.070336</td>\n",
              "      <td>0.503308</td>\n",
              "      <td>1.390995</td>\n",
              "      <td>0.204899</td>\n",
              "      <td>1.028163</td>\n",
              "      <td>-0.205379</td>\n",
              "      <td>0.041734</td>\n",
              "      <td>-0.142185</td>\n",
              "      <td>0.127815</td>\n",
              "      <td>-0.163294</td>\n",
              "      <td>0.107615</td>\n",
              "      <td>-0.261374</td>\n",
              "      <td>0.037185</td>\n",
              "      <td>0.015585</td>\n",
              "      <td>0.379035</td>\n",
              "      <td>-0.065925</td>\n",
              "      <td>0.296567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-1.797804</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>-0.26929</td>\n",
              "      <td>-0.192979</td>\n",
              "      <td>0.022002</td>\n",
              "      <td>-0.217551</td>\n",
              "      <td>d654cd67</td>\n",
              "      <td>04d863d5</td>\n",
              "      <td>7fde5a70</td>\n",
              "      <td>23c80a6e</td>\n",
              "      <td>e69eaa04</td>\n",
              "      <td>nan</td>\n",
              "      <td>fec218c0</td>\n",
              "      <td>e5ba7672</td>\n",
              "      <td>nan</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>3.725290e-09</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.139528</td>\n",
              "      <td>0.084774</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.226556</td>\n",
              "      <td>0.210647</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>1.435264e-09</td>\n",
              "      <td>-0.25866</td>\n",
              "      <td>0.011398</td>\n",
              "      <td>-0.202792</td>\n",
              "      <td>0.257610</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>3.725290e-09</td>\n",
              "      <td>-0.121732</td>\n",
              "      <td>0.070501</td>\n",
              "      <td>-0.110585</td>\n",
              "      <td>0.109100</td>\n",
              "      <td>-0.269290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.269290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.215054</td>\n",
              "      <td>0.242550</td>\n",
              "      <td>-0.242714</td>\n",
              "      <td>0.070336</td>\n",
              "      <td>0.503308</td>\n",
              "      <td>1.390995</td>\n",
              "      <td>0.214846</td>\n",
              "      <td>1.023034</td>\n",
              "      <td>-0.106444</td>\n",
              "      <td>0.181650</td>\n",
              "      <td>-0.126469</td>\n",
              "      <td>0.138029</td>\n",
              "      <td>-0.152801</td>\n",
              "      <td>0.115067</td>\n",
              "      <td>-0.252609</td>\n",
              "      <td>0.049580</td>\n",
              "      <td>-0.010709</td>\n",
              "      <td>0.385798</td>\n",
              "      <td>-0.072937</td>\n",
              "      <td>0.298502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-1.797804</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>-0.26929</td>\n",
              "      <td>0.105430</td>\n",
              "      <td>-0.250061</td>\n",
              "      <td>-0.235080</td>\n",
              "      <td>c13b3446</td>\n",
              "      <td>fffe2a63</td>\n",
              "      <td>ca280131</td>\n",
              "      <td>621dddfe</td>\n",
              "      <td>fc5dea81</td>\n",
              "      <td>nan</td>\n",
              "      <td>06373944</td>\n",
              "      <td>e5ba7672</td>\n",
              "      <td>nan</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>3.725290e-09</td>\n",
              "      <td>-0.158484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.139528</td>\n",
              "      <td>0.084774</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.273658</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.226556</td>\n",
              "      <td>0.210647</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>1.435264e-09</td>\n",
              "      <td>-0.25866</td>\n",
              "      <td>0.011398</td>\n",
              "      <td>-0.202792</td>\n",
              "      <td>0.257610</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>3.725290e-09</td>\n",
              "      <td>-0.121732</td>\n",
              "      <td>0.070501</td>\n",
              "      <td>-0.110585</td>\n",
              "      <td>0.109100</td>\n",
              "      <td>-0.269290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.269290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.215054</td>\n",
              "      <td>0.242550</td>\n",
              "      <td>-0.043775</td>\n",
              "      <td>0.211007</td>\n",
              "      <td>0.533149</td>\n",
              "      <td>1.377534</td>\n",
              "      <td>0.199926</td>\n",
              "      <td>1.022309</td>\n",
              "      <td>-0.114029</td>\n",
              "      <td>0.192377</td>\n",
              "      <td>-0.151609</td>\n",
              "      <td>0.135025</td>\n",
              "      <td>-0.152790</td>\n",
              "      <td>0.115057</td>\n",
              "      <td>-0.226316</td>\n",
              "      <td>0.012395</td>\n",
              "      <td>-0.017720</td>\n",
              "      <td>0.389532</td>\n",
              "      <td>-0.075566</td>\n",
              "      <td>0.299747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-1.797804</td>\n",
              "      <td>0.220638</td>\n",
              "      <td>0.668383</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>2.17132</td>\n",
              "      <td>-0.093510</td>\n",
              "      <td>-0.249455</td>\n",
              "      <td>0.203145</td>\n",
              "      <td>4bbb6072</td>\n",
              "      <td>65c9624a</td>\n",
              "      <td>3d80d418</td>\n",
              "      <td>bd3bc740</td>\n",
              "      <td>dd2f45db</td>\n",
              "      <td>0798bd9b</td>\n",
              "      <td>e44b5a03</td>\n",
              "      <td>3486227d</td>\n",
              "      <td>aab7b783</td>\n",
              "      <td>1</td>\n",
              "      <td>0.031077</td>\n",
              "      <td>2.680799e-01</td>\n",
              "      <td>-0.120572</td>\n",
              "      <td>0.119889</td>\n",
              "      <td>-0.120572</td>\n",
              "      <td>0.116691</td>\n",
              "      <td>0.197363</td>\n",
              "      <td>0.666124</td>\n",
              "      <td>-0.179454</td>\n",
              "      <td>0.2979</td>\n",
              "      <td>-0.179454</td>\n",
              "      <td>0.289954</td>\n",
              "      <td>-0.262264</td>\n",
              "      <td>1.435264e-09</td>\n",
              "      <td>-0.25866</td>\n",
              "      <td>0.011398</td>\n",
              "      <td>-0.202792</td>\n",
              "      <td>0.257610</td>\n",
              "      <td>-0.144026</td>\n",
              "      <td>3.725290e-09</td>\n",
              "      <td>-0.121732</td>\n",
              "      <td>0.070501</td>\n",
              "      <td>-0.110585</td>\n",
              "      <td>0.109100</td>\n",
              "      <td>0.951015</td>\n",
              "      <td>1.725772</td>\n",
              "      <td>-0.025229</td>\n",
              "      <td>0.771789</td>\n",
              "      <td>-0.093024</td>\n",
              "      <td>0.585428</td>\n",
              "      <td>0.005960</td>\n",
              "      <td>0.140671</td>\n",
              "      <td>0.543096</td>\n",
              "      <td>1.372056</td>\n",
              "      <td>0.204899</td>\n",
              "      <td>1.020537</td>\n",
              "      <td>-0.249758</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>-0.179050</td>\n",
              "      <td>0.122455</td>\n",
              "      <td>-0.152947</td>\n",
              "      <td>0.115194</td>\n",
              "      <td>-0.015968</td>\n",
              "      <td>0.309872</td>\n",
              "      <td>0.019090</td>\n",
              "      <td>0.391460</td>\n",
              "      <td>-0.049273</td>\n",
              "      <td>0.299989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    click_timestamp  integer_feature_1  ...  avg_int8_10  var_int8_10\n",
              "19        -1.797820          -0.158484  ...    -0.067678     0.298046\n",
              "20        -1.797820          -0.158484  ...    -0.065925     0.296567\n",
              "21        -1.797804          -0.158484  ...    -0.072937     0.298502\n",
              "22        -1.797804          -0.158484  ...    -0.075566     0.299747\n",
              "23        -1.797804           0.220638  ...    -0.049273     0.299989\n",
              "\n",
              "[5 rows x 67 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Xf4Yatbind"
      },
      "source": [
        "Tensorflow input data creation\n",
        "\n",
        "판다스 데이터프레임을 텐서플로 데이터셋으로 변형"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJgQjQJcNkaH"
      },
      "source": [
        "def df_to_dataset(dataframe, shuffle=False, batch_size=1000):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('label')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kpfwl6xNlDk"
      },
      "source": [
        "train_ds = df_to_dataset(final_train)\n",
        "vali_ds = df_to_dataset(final_vali)\n",
        "# test_ds = df_to_dataset(final_test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQkQwUXDOv0l"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SajYp4F6Pwkv"
      },
      "source": [
        "def demo(feature_column):\n",
        "  feature_layer = layers.DenseFeatures(feature_column)\n",
        "  print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pg-QK49PCPe"
      },
      "source": [
        "example_batch = next(iter(train_ds))[0]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-owRKfeVVwt"
      },
      "source": [
        "numeric_cols2 = ['click_timestamp', 'integer_feature_1', 'integer_feature_2',\n",
        "       'integer_feature_3', 'integer_feature_4', 'integer_feature_5',\n",
        "       'integer_feature_6', 'integer_feature_7', 'integer_feature_8','avg_int1', 'var_int1', 'avg_int1_5',\n",
        "       'var_int1_5', 'avg_int1_10', 'var_int1_10', 'avg_int2', 'var_int2',\n",
        "       'avg_int2_5', 'var_int2_5', 'avg_int2_10', 'var_int2_10', 'avg_int3',\n",
        "       'var_int3', 'avg_int3_5', 'var_int3_5', 'avg_int3_10', 'var_int3_10',\n",
        "       'avg_int4', 'var_int4', 'avg_int4_5', 'var_int4_5', 'avg_int4_10',\n",
        "       'var_int4_10', 'avg_int5', 'var_int5', 'avg_int5_5', 'var_int5_5',\n",
        "       'avg_int5_10', 'var_int5_10', 'avg_int6', 'var_int6', 'avg_int6_5',\n",
        "       'var_int6_5', 'avg_int6_10', 'var_int6_10', 'avg_int7', 'var_int7',\n",
        "       'avg_int7_5', 'var_int7_5', 'avg_int7_10', 'var_int7_10', 'avg_int8',\n",
        "       'var_int8', 'avg_int8_5', 'var_int8_5', 'avg_int8_10', 'var_int8_10']"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjKYNCCvb9dw"
      },
      "source": [
        "Feature layer creation\n",
        "\n",
        "첫 레이어에서 카테고리형 피쳐들을 임베딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn7ceVLtO0fI"
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "# 수치형 열\n",
        "for header in numeric_cols2:\n",
        "  feature_columns.append(feature_column.numeric_column(header))\n",
        "\n",
        "\n",
        "# 임베딩 열\n",
        "for cate_number in range(1,10):\n",
        "  cate = feature_column.categorical_column_with_vocabulary_list(\n",
        "        'categorical_feature_'+str(cate_number), np.unique(final_train['categorical_feature_'+str(cate_number)]))\n",
        "  cate_embedding = feature_column.embedding_column(cate, dimension=100)\n",
        "  feature_columns.append(cate_embedding)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNQuEAQ1Rb6N"
      },
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpcQCifRmz85"
      },
      "source": [
        "Modeling\n",
        "\n",
        "모델링의 핵심적인 이슈는 오버피팅이였으며, 이를 해결하기위해 0.7이상의 dropout과 0.01이상의 regularization 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JlpkkTFRn4v"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LFEwSwdVrhP",
        "outputId": "4544000c-fc39-47b3-e7cd-67d991b82e40"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  feature_layer,\n",
        "  # tf.keras.layers.Dropout(0.5),\n",
        "  # tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-2)),  \n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-2)),  \n",
        "  tf.keras.layers.Dropout(0.7),\n",
        "  tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-1)),  \n",
        "  tf.keras.layers.Dropout(0.8),  \n",
        "  layers.Dense(1, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(1e-4))\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "          validation_data=vali_ds,\n",
        "          epochs=10, \n",
        "          batch_size=1000,\n",
        "          verbose=1, \n",
        "          shuffle=True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'click_timestamp': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float64>, 'integer_feature_1': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float64>, 'integer_feature_2': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float64>, 'integer_feature_3': <tf.Tensor 'ExpandDims_36:0' shape=(None, 1) dtype=float64>, 'integer_feature_4': <tf.Tensor 'ExpandDims_37:0' shape=(None, 1) dtype=float64>, 'integer_feature_5': <tf.Tensor 'ExpandDims_38:0' shape=(None, 1) dtype=float64>, 'integer_feature_6': <tf.Tensor 'ExpandDims_39:0' shape=(None, 1) dtype=float64>, 'integer_feature_7': <tf.Tensor 'ExpandDims_40:0' shape=(None, 1) dtype=float64>, 'integer_feature_8': <tf.Tensor 'ExpandDims_41:0' shape=(None, 1) dtype=float64>, 'categorical_feature_1': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=string>, 'categorical_feature_2': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'categorical_feature_3': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'categorical_feature_4': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'categorical_feature_5': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=string>, 'categorical_feature_6': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'categorical_feature_7': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=string>, 'categorical_feature_8': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=string>, 'categorical_feature_9': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=string>, 'avg_int1': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'var_int1': <tf.Tensor 'ExpandDims_42:0' shape=(None, 1) dtype=float64>, 'avg_int1_5': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'var_int1_5': <tf.Tensor 'ExpandDims_44:0' shape=(None, 1) dtype=float64>, 'avg_int1_10': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'var_int1_10': <tf.Tensor 'ExpandDims_43:0' shape=(None, 1) dtype=float64>, 'avg_int2': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'var_int2': <tf.Tensor 'ExpandDims_45:0' shape=(None, 1) dtype=float64>, 'avg_int2_5': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'var_int2_5': <tf.Tensor 'ExpandDims_47:0' shape=(None, 1) dtype=float64>, 'avg_int2_10': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'var_int2_10': <tf.Tensor 'ExpandDims_46:0' shape=(None, 1) dtype=float64>, 'avg_int3': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'var_int3': <tf.Tensor 'ExpandDims_48:0' shape=(None, 1) dtype=float64>, 'avg_int3_5': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'var_int3_5': <tf.Tensor 'ExpandDims_50:0' shape=(None, 1) dtype=float64>, 'avg_int3_10': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'var_int3_10': <tf.Tensor 'ExpandDims_49:0' shape=(None, 1) dtype=float64>, 'avg_int4': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'var_int4': <tf.Tensor 'ExpandDims_51:0' shape=(None, 1) dtype=float64>, 'avg_int4_5': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'var_int4_5': <tf.Tensor 'ExpandDims_53:0' shape=(None, 1) dtype=float64>, 'avg_int4_10': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'var_int4_10': <tf.Tensor 'ExpandDims_52:0' shape=(None, 1) dtype=float64>, 'avg_int5': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'var_int5': <tf.Tensor 'ExpandDims_54:0' shape=(None, 1) dtype=float64>, 'avg_int5_5': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'var_int5_5': <tf.Tensor 'ExpandDims_56:0' shape=(None, 1) dtype=float64>, 'avg_int5_10': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'var_int5_10': <tf.Tensor 'ExpandDims_55:0' shape=(None, 1) dtype=float64>, 'avg_int6': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'var_int6': <tf.Tensor 'ExpandDims_57:0' shape=(None, 1) dtype=float64>, 'avg_int6_5': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'var_int6_5': <tf.Tensor 'ExpandDims_59:0' shape=(None, 1) dtype=float64>, 'avg_int6_10': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'var_int6_10': <tf.Tensor 'ExpandDims_58:0' shape=(None, 1) dtype=float64>, 'avg_int7': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'var_int7': <tf.Tensor 'ExpandDims_60:0' shape=(None, 1) dtype=float64>, 'avg_int7_5': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'var_int7_5': <tf.Tensor 'ExpandDims_62:0' shape=(None, 1) dtype=float64>, 'avg_int7_10': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'var_int7_10': <tf.Tensor 'ExpandDims_61:0' shape=(None, 1) dtype=float64>, 'avg_int8': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'var_int8': <tf.Tensor 'ExpandDims_63:0' shape=(None, 1) dtype=float64>, 'avg_int8_5': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float64>, 'var_int8_5': <tf.Tensor 'ExpandDims_65:0' shape=(None, 1) dtype=float64>, 'avg_int8_10': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'var_int8_10': <tf.Tensor 'ExpandDims_64:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'click_timestamp': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float64>, 'integer_feature_1': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float64>, 'integer_feature_2': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float64>, 'integer_feature_3': <tf.Tensor 'ExpandDims_36:0' shape=(None, 1) dtype=float64>, 'integer_feature_4': <tf.Tensor 'ExpandDims_37:0' shape=(None, 1) dtype=float64>, 'integer_feature_5': <tf.Tensor 'ExpandDims_38:0' shape=(None, 1) dtype=float64>, 'integer_feature_6': <tf.Tensor 'ExpandDims_39:0' shape=(None, 1) dtype=float64>, 'integer_feature_7': <tf.Tensor 'ExpandDims_40:0' shape=(None, 1) dtype=float64>, 'integer_feature_8': <tf.Tensor 'ExpandDims_41:0' shape=(None, 1) dtype=float64>, 'categorical_feature_1': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=string>, 'categorical_feature_2': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'categorical_feature_3': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'categorical_feature_4': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'categorical_feature_5': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=string>, 'categorical_feature_6': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'categorical_feature_7': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=string>, 'categorical_feature_8': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=string>, 'categorical_feature_9': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=string>, 'avg_int1': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'var_int1': <tf.Tensor 'ExpandDims_42:0' shape=(None, 1) dtype=float64>, 'avg_int1_5': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'var_int1_5': <tf.Tensor 'ExpandDims_44:0' shape=(None, 1) dtype=float64>, 'avg_int1_10': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'var_int1_10': <tf.Tensor 'ExpandDims_43:0' shape=(None, 1) dtype=float64>, 'avg_int2': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'var_int2': <tf.Tensor 'ExpandDims_45:0' shape=(None, 1) dtype=float64>, 'avg_int2_5': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'var_int2_5': <tf.Tensor 'ExpandDims_47:0' shape=(None, 1) dtype=float64>, 'avg_int2_10': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'var_int2_10': <tf.Tensor 'ExpandDims_46:0' shape=(None, 1) dtype=float64>, 'avg_int3': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'var_int3': <tf.Tensor 'ExpandDims_48:0' shape=(None, 1) dtype=float64>, 'avg_int3_5': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'var_int3_5': <tf.Tensor 'ExpandDims_50:0' shape=(None, 1) dtype=float64>, 'avg_int3_10': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'var_int3_10': <tf.Tensor 'ExpandDims_49:0' shape=(None, 1) dtype=float64>, 'avg_int4': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'var_int4': <tf.Tensor 'ExpandDims_51:0' shape=(None, 1) dtype=float64>, 'avg_int4_5': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'var_int4_5': <tf.Tensor 'ExpandDims_53:0' shape=(None, 1) dtype=float64>, 'avg_int4_10': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'var_int4_10': <tf.Tensor 'ExpandDims_52:0' shape=(None, 1) dtype=float64>, 'avg_int5': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'var_int5': <tf.Tensor 'ExpandDims_54:0' shape=(None, 1) dtype=float64>, 'avg_int5_5': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'var_int5_5': <tf.Tensor 'ExpandDims_56:0' shape=(None, 1) dtype=float64>, 'avg_int5_10': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'var_int5_10': <tf.Tensor 'ExpandDims_55:0' shape=(None, 1) dtype=float64>, 'avg_int6': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'var_int6': <tf.Tensor 'ExpandDims_57:0' shape=(None, 1) dtype=float64>, 'avg_int6_5': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'var_int6_5': <tf.Tensor 'ExpandDims_59:0' shape=(None, 1) dtype=float64>, 'avg_int6_10': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'var_int6_10': <tf.Tensor 'ExpandDims_58:0' shape=(None, 1) dtype=float64>, 'avg_int7': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'var_int7': <tf.Tensor 'ExpandDims_60:0' shape=(None, 1) dtype=float64>, 'avg_int7_5': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'var_int7_5': <tf.Tensor 'ExpandDims_62:0' shape=(None, 1) dtype=float64>, 'avg_int7_10': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'var_int7_10': <tf.Tensor 'ExpandDims_61:0' shape=(None, 1) dtype=float64>, 'avg_int8': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'var_int8': <tf.Tensor 'ExpandDims_63:0' shape=(None, 1) dtype=float64>, 'avg_int8_5': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float64>, 'var_int8_5': <tf.Tensor 'ExpandDims_65:0' shape=(None, 1) dtype=float64>, 'avg_int8_10': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'var_int8_10': <tf.Tensor 'ExpandDims_64:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2536/2537 [============================>.] - ETA: 0s - loss: 1.1232 - accuracy: 0.7885WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'click_timestamp': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float64>, 'integer_feature_1': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float64>, 'integer_feature_2': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float64>, 'integer_feature_3': <tf.Tensor 'ExpandDims_36:0' shape=(None, 1) dtype=float64>, 'integer_feature_4': <tf.Tensor 'ExpandDims_37:0' shape=(None, 1) dtype=float64>, 'integer_feature_5': <tf.Tensor 'ExpandDims_38:0' shape=(None, 1) dtype=float64>, 'integer_feature_6': <tf.Tensor 'ExpandDims_39:0' shape=(None, 1) dtype=float64>, 'integer_feature_7': <tf.Tensor 'ExpandDims_40:0' shape=(None, 1) dtype=float64>, 'integer_feature_8': <tf.Tensor 'ExpandDims_41:0' shape=(None, 1) dtype=float64>, 'categorical_feature_1': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=string>, 'categorical_feature_2': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'categorical_feature_3': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'categorical_feature_4': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'categorical_feature_5': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=string>, 'categorical_feature_6': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'categorical_feature_7': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=string>, 'categorical_feature_8': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=string>, 'categorical_feature_9': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=string>, 'avg_int1': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'var_int1': <tf.Tensor 'ExpandDims_42:0' shape=(None, 1) dtype=float64>, 'avg_int1_5': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'var_int1_5': <tf.Tensor 'ExpandDims_44:0' shape=(None, 1) dtype=float64>, 'avg_int1_10': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'var_int1_10': <tf.Tensor 'ExpandDims_43:0' shape=(None, 1) dtype=float64>, 'avg_int2': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'var_int2': <tf.Tensor 'ExpandDims_45:0' shape=(None, 1) dtype=float64>, 'avg_int2_5': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'var_int2_5': <tf.Tensor 'ExpandDims_47:0' shape=(None, 1) dtype=float64>, 'avg_int2_10': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'var_int2_10': <tf.Tensor 'ExpandDims_46:0' shape=(None, 1) dtype=float64>, 'avg_int3': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'var_int3': <tf.Tensor 'ExpandDims_48:0' shape=(None, 1) dtype=float64>, 'avg_int3_5': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'var_int3_5': <tf.Tensor 'ExpandDims_50:0' shape=(None, 1) dtype=float64>, 'avg_int3_10': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'var_int3_10': <tf.Tensor 'ExpandDims_49:0' shape=(None, 1) dtype=float64>, 'avg_int4': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'var_int4': <tf.Tensor 'ExpandDims_51:0' shape=(None, 1) dtype=float64>, 'avg_int4_5': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'var_int4_5': <tf.Tensor 'ExpandDims_53:0' shape=(None, 1) dtype=float64>, 'avg_int4_10': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'var_int4_10': <tf.Tensor 'ExpandDims_52:0' shape=(None, 1) dtype=float64>, 'avg_int5': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'var_int5': <tf.Tensor 'ExpandDims_54:0' shape=(None, 1) dtype=float64>, 'avg_int5_5': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'var_int5_5': <tf.Tensor 'ExpandDims_56:0' shape=(None, 1) dtype=float64>, 'avg_int5_10': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'var_int5_10': <tf.Tensor 'ExpandDims_55:0' shape=(None, 1) dtype=float64>, 'avg_int6': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'var_int6': <tf.Tensor 'ExpandDims_57:0' shape=(None, 1) dtype=float64>, 'avg_int6_5': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'var_int6_5': <tf.Tensor 'ExpandDims_59:0' shape=(None, 1) dtype=float64>, 'avg_int6_10': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'var_int6_10': <tf.Tensor 'ExpandDims_58:0' shape=(None, 1) dtype=float64>, 'avg_int7': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'var_int7': <tf.Tensor 'ExpandDims_60:0' shape=(None, 1) dtype=float64>, 'avg_int7_5': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'var_int7_5': <tf.Tensor 'ExpandDims_62:0' shape=(None, 1) dtype=float64>, 'avg_int7_10': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'var_int7_10': <tf.Tensor 'ExpandDims_61:0' shape=(None, 1) dtype=float64>, 'avg_int8': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'var_int8': <tf.Tensor 'ExpandDims_63:0' shape=(None, 1) dtype=float64>, 'avg_int8_5': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float64>, 'var_int8_5': <tf.Tensor 'ExpandDims_65:0' shape=(None, 1) dtype=float64>, 'avg_int8_10': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'var_int8_10': <tf.Tensor 'ExpandDims_64:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2537/2537 [==============================] - 145s 56ms/step - loss: 1.1228 - accuracy: 0.7885 - val_loss: 0.4114 - val_accuracy: 0.8267\n",
            "Epoch 2/10\n",
            "2537/2537 [==============================] - 138s 54ms/step - loss: 0.4309 - accuracy: 0.8142 - val_loss: 0.4004 - val_accuracy: 0.8330\n",
            "Epoch 3/10\n",
            "2537/2537 [==============================] - 130s 51ms/step - loss: 0.4252 - accuracy: 0.8170 - val_loss: 0.4061 - val_accuracy: 0.8273\n",
            "Epoch 4/10\n",
            "2537/2537 [==============================] - 127s 50ms/step - loss: 0.4236 - accuracy: 0.8173 - val_loss: 0.4059 - val_accuracy: 0.8283\n",
            "Epoch 5/10\n",
            "2537/2537 [==============================] - 127s 50ms/step - loss: 0.4214 - accuracy: 0.8186 - val_loss: 0.4018 - val_accuracy: 0.8315\n",
            "Epoch 6/10\n",
            "2537/2537 [==============================] - 125s 49ms/step - loss: 0.4203 - accuracy: 0.8196 - val_loss: 0.4010 - val_accuracy: 0.8336\n",
            "Epoch 7/10\n",
            "2537/2537 [==============================] - 125s 49ms/step - loss: 0.4192 - accuracy: 0.8201 - val_loss: 0.4035 - val_accuracy: 0.8336\n",
            "Epoch 8/10\n",
            "2537/2537 [==============================] - 126s 50ms/step - loss: 0.4182 - accuracy: 0.8208 - val_loss: 0.4042 - val_accuracy: 0.8351\n",
            "Epoch 9/10\n",
            "2537/2537 [==============================] - 127s 50ms/step - loss: 0.4174 - accuracy: 0.8216 - val_loss: 0.4069 - val_accuracy: 0.8348\n",
            "Epoch 10/10\n",
            "2537/2537 [==============================] - 125s 49ms/step - loss: 0.4165 - accuracy: 0.8218 - val_loss: 0.4069 - val_accuracy: 0.8359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe-OyhMsWoKO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "e1ca24a0-d8b8-49f6-ce92-805d5f8c6614"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'][0:], label='Loss')\n",
        "plt.plot(history.history['val_loss'][0:], label='Val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjN8TiTkWIid",
        "outputId": "ec74fd19-719b-451a-f3b3-7d6477cbec29"
      },
      "source": [
        "loss, accuracy = model.evaluate(vali_ds)\n",
        "print(\"정확도\", accuracy)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "494/494 [==============================] - 18s 35ms/step - loss: 0.4069 - accuracy: 0.8359\n",
            "정확도 0.8358511924743652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-edgN4YBV_s"
      },
      "source": [
        "* Test dataset prediction을 위한 최종 모델은 train과 validation datasets을 결합하여 모델을 다시 훈련하였으며, 과정은 위와 동일함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B35MUbIkX-I"
      },
      "source": [
        "y_pred = model.predict(x_vali)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}